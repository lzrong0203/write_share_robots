# é‡‘èæƒ…ç·’åˆ†æèˆ‡Pythonæ‡‰ç”¨

## ç¬¬ä¸€ç« ï¼šæƒ…ç·’æŒ‡æ•¸çš„åŸºç¤æ¦‚å¿µ

### 1-1 æƒ…ç·’åˆ†ææ¦‚è¿°
- å®šç¾©ï¼šæƒ…ç·’åˆ†æ(sentiment analysis)æ˜¯åˆ©ç”¨è‡ªç„¶èªè¨€è™•ç†æŠ€è¡“åˆ¤æ–·æ–‡å­—ä¸­çš„æƒ…æ„Ÿå‚¾å‘
- æ‡‰ç”¨ç›®çš„ï¼šå¾éçµæ§‹åŒ–æ–‡å­—ä¸­èƒå–å¸‚å ´æƒ…ç·’ã€æŠ•è³‡æ´è¦‹
- æ ¸å¿ƒåƒ¹å€¼ï¼šå¸‚å ´å—æƒ…ç·’é©…å‹•ï¼Œæƒ…ç·’æ³¢å‹•å¾€å¾€é ˜å…ˆåƒ¹æ ¼è®Šå‹•
- è™•ç†æµç¨‹ï¼šè³‡æ–™è’é›† â†’ æ–‡å­—é è™•ç† â†’ æƒ…ç·’åˆ†é¡ â†’ æŒ‡æ•¸è¨ˆç®—

### 1-2 æƒ…ç·’åˆ†æçš„é¡å‹
- æ–‡ä»¶ç´šåˆ†æï¼šæ•´ç¯‡æ–‡ç« çš„ç¸½é«”æƒ…ç·’ï¼ˆå¦‚æ–°èå ±å°çš„æ­£è² é¢ï¼‰
- å¥å­ç´šåˆ†æï¼šå–®å¥è©•è«–çš„æƒ…ç·’å‚¾å‘ï¼ˆå¦‚æ¨æ–‡æƒ…ç·’ï¼‰
- å¯¦é«”/æ–¹é¢ç´šåˆ†æï¼šé‡å°ç‰¹å®šç›®æ¨™çš„æƒ…ç·’ï¼ˆå¦‚å°ã€Œç²åˆ©ã€ã€Œæˆé•·æ€§ã€çš„è©•åƒ¹ï¼‰
- ç´°ç²’åº¦æƒ…ç·’åˆ†æï¼šå€åˆ†è©³ç´°æƒ…ç·’é¡åˆ¥ï¼ˆå–œæ‚…ã€æ†¤æ€’ã€é©šè¨ç­‰ï¼‰
- æƒ…ç·’å¼·åº¦åˆ†æï¼šè©•ä¼°æƒ…ç·’çš„å¼·çƒˆç¨‹åº¦ï¼ˆå¼·çƒˆ/è¼•å¾®æ­£è² é¢ç­‰ï¼‰

### 1-3 é‡‘èæƒ…ç·’æŒ‡æ•¸ç‰¹æ€§
- å®šç¾©ï¼šé‡åŒ–æŠ•è³‡äººå°å¸‚å ´æˆ–å€‹è‚¡çš„æƒ…æ„Ÿ/æ…‹åº¦çš„æ•¸å€¼æŒ‡æ¨™
- å¸¸è¦‹ä¾†æºï¼šç¤¾ç¾¤åª’é«”ã€æ–°èå ±å°ã€åˆ†æå¸«å ±å‘Šã€å…¬å¸å…¬å‘Š
- è¨ˆç®—æ–¹å¼ï¼šå°‡æ–‡å­—æƒ…ç·’åˆ†æ•¸åŠ æ¬Šå¹³å‡ï¼Œé€šå¸¸ä»¥-1(æ¥µè² é¢)åˆ°1(æ¥µæ­£é¢)è¡¨ç¤º
- æ‡‰ç”¨å ´æ™¯ï¼šé¢¨éšªé è­¦ã€è¶¨å‹¢ç¢ºèªã€é€†å‹¢äº¤æ˜“è¨Šè™Ÿ
- ä»£è¡¨æ€§æŒ‡æ¨™ï¼šææ‡¼èˆ‡è²ªå©ªæŒ‡æ•¸ã€VIXææ…ŒæŒ‡æ•¸ã€ç¤¾ç¾¤æƒ…ç·’æŒ‡æ¨™

### 1-4 é‡‘èæƒ…ç·’åˆ†æçš„æŒ‘æˆ°
- é ˜åŸŸå°ˆæ¥­æ€§ï¼šé‡‘èå°ˆæ¥­è¡“èªèˆ‡è¡Œè©±ï¼ˆå¦‚ã€Œç²åˆ©é è­¦ã€ã€Œå¥åº·ä¿®æ­£ã€ï¼‰
- éš±å«æƒ…ç·’ï¼šå¸‚å ´å ±å°é€šå¸¸æªè¾­å®¢è§€ï¼Œæƒ…ç·’è¡¨é”å«è“„
- åè«·èˆ‡è«·åˆºï¼šã€Œé€™æª”è‚¡ç¥¨ç©©ç©©ç™¼å¤§è²¡ã€å¯èƒ½æ˜¯è² é¢è¡¨é”
- å¤šé‡ç›®æ¨™ï¼šåŒä¸€æ–‡å­—ä¸­å°ä¸åŒè‚¡ç¥¨/æŒ‡æ¨™çš„æƒ…ç·’å¯èƒ½ä¸åŒ
- æ™‚æ•ˆæ€§å¼·ï¼šå¸‚å ´æƒ…ç·’ç¬æ¯è¬è®Šï¼Œåˆ†æéœ€å³æ™‚æ€§

## ç¬¬äºŒç« ï¼šè‡ªç„¶èªè¨€è™•ç†èˆ‡ç›¸é—œAIæ¨¡å‹

### 2-1 NLPåŸºç¤æŠ€è¡“
- æ–‡å­—é è™•ç†ï¼šæ–·è©/åˆ†è©ã€å»é™¤åœç”¨è©ã€è©å½¢é‚„åŸ
- æ–‡å­—è¡¨ç¤ºï¼šè©è¢‹æ¨¡å‹(Bag-of-Words)ã€è©é »-é€†æ–‡ä»¶é »ç‡(TF-IDF)
- ç‰¹å¾µå·¥ç¨‹ï¼šn-gramå»ºæ¨¡ã€è©æ€§æ¨™è¨»ã€å‘½åå¯¦é«”è­˜åˆ¥
- åŸºç¤æ¨¡å‹ï¼šå­—å…¸æ³•ã€æ©Ÿå™¨å­¸ç¿’åˆ†é¡(å¦‚SVMã€éš¨æ©Ÿæ£®æ—ç­‰)

### 2-2 è©å…¸èˆ‡è¦å‰‡æ–¹æ³•
- å¸¸ç”¨å·¥å…·ï¼šVADERã€TextBlobã€SentiStrength
- åŸç†ï¼šåŸºæ–¼æƒ…æ„Ÿè©å…¸èˆ‡èªæ³•è¦å‰‡è¨ˆç®—æƒ…æ„Ÿåˆ†æ•¸
- å„ªé»ï¼šé€Ÿåº¦å¿«ã€ç„¡éœ€è¨“ç·´ã€è§£é‡‹æ€§å¼·
- å±€é™ï¼šå°èªå¢ƒã€åè«·æ•æ„Ÿåº¦ä½ï¼Œé›£è™•ç†é‡‘èå°ˆæ¥­è©å½™
- ç¯„ä¾‹ï¼šã€Œå°ç©é›»æ³•èªªé‡‹å‡ºè¬¹æ…å±•æœ›ã€é›£ä»¥æº–ç¢ºåˆ¤æ–·

### 2-3 è©åµŒå…¥èˆ‡Transformeré©å‘½
- è©åµŒå…¥ï¼šWord2Vecã€GloVeã€FastTextç­‰å°‡è©è½‰ç‚ºèªç¾©å‘é‡
- Transformeræ¶æ§‹ï¼š2017å¹´æå‡ºï¼ŒåŸºæ–¼è‡ªæ³¨æ„åŠ›æ©Ÿåˆ¶(Self-Attention)
- å„ªå‹¢ï¼šæ•æ‰é•·è·é›¢è©å½™é—œä¿‚ï¼Œç†è§£ä¸Šä¸‹æ–‡èªå¢ƒ
- æ¶æ§‹ç‰¹é»ï¼š
  - è‡ªæ³¨æ„åŠ›æ©Ÿåˆ¶ï¼šåŒæ™‚è™•ç†æ‰€æœ‰è©å½™ï¼Œå‹•æ…‹æ±ºå®šé‡è¦æ€§
  - å¤šé ­æ³¨æ„åŠ›ï¼šå¾ä¸åŒè§’åº¦ç†è§£æ–‡å­—
  - ä½ç½®ç·¨ç¢¼ï¼šä¿ç•™è©åºè³‡è¨Š

### 2-4 BERTèˆ‡é›™å‘æ¨¡å‹
- BERT (2018)ï¼šBidirectional Encoder Representations from Transformers
- ç‰¹é»ï¼šé›™å‘èªå¢ƒç†è§£ï¼Œé è¨“ç·´+å¾®èª¿ç¯„å¼
- é è¨“ç·´ä»»å‹™ï¼šé®ç½©èªè¨€æ¨¡å‹(MLM)ã€ä¸‹ä¸€å¥é æ¸¬(NSP)
- é‡‘èé ˜åŸŸè®Šé«”ï¼šFinBERTã€BloombergGPTå°ˆç‚ºè²¡ç¶“æ–‡å­—å„ªåŒ–
- é©ç”¨å ´æ™¯ï¼šé‡‘èæ–°èåˆ†é¡ã€ç›ˆé¤˜å ±å‘Šæƒ…ç·’åˆ†æã€åˆ†æå¸«å ±å‘Šè§£è®€

### 2-5 GPTèˆ‡ç”Ÿæˆæ¨¡å‹
- GPT (Generative Pre-trained Transformer)ï¼šè‡ªå›æ­¸èªè¨€æ¨¡å‹
- æ¶æ§‹ç‰¹é»ï¼šåƒ…ä½¿ç”¨Transformerè§£ç¢¼å™¨ï¼Œå–®å‘é æ¸¬ä¸‹ä¸€å€‹è©
- èˆ‡BERTå·®ç•°ï¼šç”Ÿæˆvs.ç†è§£ï¼Œå–®å‘vs.é›™å‘
- å„ªå‹¢ï¼š
  - é›¶æ¨£æœ¬/å°‘æ¨£æœ¬å­¸ç¿’èƒ½åŠ›å¼·
  - æƒ…æ„Ÿåˆ†æåŒæ™‚èƒ½æä¾›è§£é‡‹
  - é©æ‡‰æ–°èªå¢ƒèˆ‡é ˜åŸŸçš„èƒ½åŠ›ä½³
- æ‡‰ç”¨ï¼šæƒ…ç·’åˆ¤æ–·ã€è²¡å ±æ‘˜è¦ã€å¸‚å ´è©•è«–ç”Ÿæˆ

### 2-6 é–‹æºå¤§å‹èªè¨€æ¨¡å‹
- LLaMA (Meta)ï¼šé«˜æ•ˆèƒ½é–‹æºå¤§å‹èªè¨€æ¨¡å‹
- å„ªå‹¢ï¼šå¯æœ¬åœ°éƒ¨ç½²ã€é¿å…APIæˆæœ¬ã€ä¿è­·è³‡æ–™éš±ç§
- å¾®èª¿æ–¹æ³•ï¼šLoRA (Low-Rank Adaptation)åƒæ•¸é«˜æ•ˆå¾®èª¿
- é‡‘èé ˜åŸŸæ‡‰ç”¨ï¼šå¯é‡å°æœ¬åœ°å¸‚å ´ç‰¹è‰²é€²è¡Œå„ªåŒ–
- éƒ¨ç½²è€ƒé‡ï¼šè¨ˆç®—è³‡æºéœ€æ±‚ã€æ¨è«–é€Ÿåº¦ã€ç¶­è­·æˆæœ¬

## ç¬¬ä¸‰ç« ï¼šç¤¾ç¾¤è¨è«–ã€é‡å¤§è¨Šæ¯èˆ‡æ–°èå ±å°çš„æƒ…ç·’æŒ‡æ•¸

### 3-1 ç¤¾ç¾¤åª’é«”æƒ…ç·’åˆ†æ
- ä¸»è¦å¹³å°ï¼šX(Twitter)ã€Redditã€PTTã€Dcardç­‰
- æ–‡å­—ç‰¹é»ï¼š
  - éæ­£å¼èªè¨€ã€å£èªåŒ–è¡¨é”
  - å¤§é‡è¡¨æƒ…ç¬¦è™Ÿã€ç¸®å¯«ã€ä¿šèª
  - æ–‡å­—æ¥µçŸ­ä¸”é›œè¨Šå¤š
  - è«·åˆºèˆ‡åè«·å¸¸è¦‹
- æŒ‘æˆ°ï¼š
  - èªè¨€å¤šè®Šæ€§ï¼ˆæ–°è©ã€æµè¡Œèªï¼‰
  - è¡¨æƒ…ç¬¦è™Ÿèªç¾©ï¼ˆğŸ˜‚â†’æ­£é¢ã€ğŸ˜¡â†’è² é¢ï¼‰
  - å³æ™‚æ€§è¦æ±‚é«˜
- å„ªå‹¢ï¼šåæ˜ æ•£æˆ¶æƒ…ç·’ã€å³æ™‚å¸‚å ´åæ‡‰ã€è¶¨å‹¢æ—©æœŸè¨Šè™Ÿ

### 3-2 ç¤¾ç¾¤æ–‡å­—è™•ç†æŠ€è¡“
- è³‡æ–™è’é›†ï¼šå¹³å°APIã€çˆ¬èŸ²æŠ€è¡“ã€ç¬¬ä¸‰æ–¹è³‡æ–™æœå‹™
- ç‰¹æ®Šé è™•ç†ï¼š
  - è¡¨æƒ…ç¬¦è™Ÿæ˜ å°„ï¼ˆè½‰æ›ç‚ºæ–‡å­—æƒ…æ„Ÿå€¼ï¼‰
  - ç¸®å¯«å±•é–‹ï¼ˆå¦‚LOLâ†’laughing out loudï¼‰
  - éŒ¯åˆ¥å­—ä¿®æ­£ã€æ¨™æº–åŒ–è™•ç†
- å·®ç•°åŒ–æ¬Šé‡è¨­è¨ˆï¼š
  - ç™¼è¨€è€…å½±éŸ¿åŠ›ï¼ˆå¦‚PageRankæ¼”ç®—æ³•ï¼‰
  - æ­·å²æº–ç¢ºåº¦åŠ æ¬Š
  - ç¤¾äº¤ç¶²çµ¡ä¸­å¿ƒåº¦
- æ™‚é–“è¡°æ¸›å‡½æ•¸ï¼šæŒ‡æ•¸è¡°æ¸›æ§åˆ¶è³‡è¨Šæ™‚æ•ˆæ€§

### 3-3 æ–°èå ±å°æƒ…ç·’åˆ†æ
- ä¾†æºé¡å‹ï¼šè²¡ç¶“åª’é«”ã€å…¬å¸å…¬å‘Šã€åˆ†æå¸«å ±å‘Š
- æ–‡å­—ç‰¹é»ï¼š
  - èªè¨€æ­£å¼ã€çµæ§‹æ€§å¼·
  - æƒ…æ„Ÿè¡¨é”éš±æ™¦ã€æªè¾­å®¢è§€
  - åŒ…å«è±å¯ŒèƒŒæ™¯è³‡è¨Š
  - æ¶‰åŠå¤šå€‹å¯¦é«”èˆ‡äº‹ä»¶
- æŒ‘æˆ°ï¼š
  - åª’é«”ç«‹å ´åèª¤
  - å°ˆæ¥­è¡“èªç†è§£
  - éš±å«æƒ…ç·’è¾¨è­˜
- å„ªå‹¢ï¼šé›œè¨Šå°‘ã€è³‡è¨Šåƒ¹å€¼é«˜ã€è¦†è“‹é¢å»£

### 3-4 é‡å¤§è¨Šæ¯èˆ‡å…¬å‘Šåˆ†æ
- é¡å‹ï¼šè²¡å ±ã€é‡å¤§äº¤æ˜“ã€ç®¡ç†å±¤è®Šå‹•ã€ç”¢å“ç™¼å¸ƒ
- ç‰¹é»ï¼š
  - é«˜åº¦çµæ§‹åŒ–ã€æ­£å¼èªè¨€
  - èˆ‡å¸‚å ´é æœŸæ¯”è¼ƒè‡³é—œé‡è¦
  - æƒ…ç·’åæ‡‰å¸¸èˆ‡é æœŸèƒŒé›¢
- åˆ†ææŠ€è¡“ï¼š
  - æ¯”è¼ƒåˆ†æï¼ˆèˆ‡é æœŸã€æ­·å²è³‡æ–™å°æ¯”ï¼‰
  - é—œéµæŒ‡æ¨™æå–
  - ç•°å¸¸è¡¨è¿°è­˜åˆ¥
- äº‹ä»¶ç ”ç©¶æ³•ï¼šåˆ†æå…¬å‘Šå‰å¾Œçš„æƒ…ç·’è®ŠåŒ–

### 3-5 å¤šä¾†æºæƒ…ç·’èåˆ
- æ¬Šé‡ç­–ç•¥ï¼š
  - ä¾†æºå¯ä¿¡åº¦åŠ æ¬Š
  - è³‡è¨Šæ–°é®®åº¦ï¼ˆæ™‚é–“è¡°æ¸›ï¼‰
  - æ–‡å­—å“è³ªè©•åˆ†
- è·¨å¸‚å ´æƒ…ç·’å‚³å°ï¼š
  - VARæ¨¡å‹æ•æ‰å¸‚å ´é–“æƒ…ç·’é€£å‹•æ€§
  - ä¸»è¦å¸‚å ´æƒ…ç·’é ˜å…ˆæŒ‡æ¨™ï¼ˆç¾è‚¡â†’å°è‚¡ï¼‰
  - è·¨åŸŸæƒ…ç·’æº¢å‡ºæ•ˆæ‡‰
- ç¶œåˆæƒ…ç·’æŒ‡æ¨™ï¼šæŠ€è¡“æŒ‡æ¨™èˆ‡æƒ…ç·’æŒ‡æ¨™èåˆ

### 3-6 å°ç£å¸‚å ´æƒ…ç·’åˆ†ææ¡ˆä¾‹
- ç‰¹è‰²å¹³å°ï¼šPTT Stockã€å°è‚¡è«–å£‡ã€è²¡ç¶“è¨è«–å€
- å°ç£å¸‚å ´å°ˆæœ‰è©å½™ï¼šã€Œæ‘¸é ­ã€ã€ã€Œé•·ç´…ã€ã€ã€Œå¡«æ¯ã€ç­‰
- ä¸­æ–‡è™•ç†æŒ‘æˆ°ï¼š
  - ç„¡ç©ºæ ¼æ–·è©ï¼ˆä½¿ç”¨jiebaç­‰å·¥å…·ï¼‰
  - ç¹ç°¡é«”æ··ç”¨
  - åœ°åŸŸæ€§è¡¨é”èˆ‡ä¿šèª
- æ•´åˆç­–ç•¥ï¼šå°è‚¡æŠ€è¡“é¢+åŸºæœ¬é¢+æƒ…ç·’é¢å¤šç¶­åˆ†æ

## ç¬¬å››ç« ï¼šChatGPTèˆ‡Python API

### 4-1 ChatGPTåŸºæœ¬æ¦‚å¿µ
- å®šç¾©ï¼šåŸºæ–¼GPTæ¶æ§‹çš„å°è©±å‹AI
- æ ¸å¿ƒèƒ½åŠ›ï¼šæ–‡å­—ç†è§£ã€ç”Ÿæˆã€æ‘˜è¦ã€åˆ†æ
- å„ªå‹¢ï¼š
  - ç†è§£èªå¢ƒèƒ½åŠ›å¼·
  - è™•ç†è¤‡é›œæŒ‡ä»¤
  - æŒæ¡å»£æ³›é ˜åŸŸçŸ¥è­˜ï¼ˆå«é‡‘èï¼‰
  - å¤šèªè¨€æ”¯æ´
- é™åˆ¶ï¼š
  - çŸ¥è­˜æˆªæ­¢æ—¥æœŸ
  - å¹»è¦ºï¼ˆè™›æ§‹å…§å®¹ï¼‰
  - æ¨¡å‹æ¨ç†ä¸é€æ˜

### 4-2 OpenAI APIæ¦‚è¿°
- APIçµæ§‹ï¼šç«¯é»ã€æ¨¡å‹ã€åƒæ•¸
- ä¸»è¦æ¨¡å‹ï¼š
  - GPT-4ï¼šæœ€å¼·å¤§ï¼Œæº–ç¢ºåº¦é«˜ä½†æˆæœ¬é«˜
  - GPT-3.5 Turboï¼šå¹³è¡¡æ•ˆèƒ½èˆ‡æˆæœ¬
  - å…¶ä»–å°ˆç”¨æ¨¡å‹ï¼šåµŒå…¥ã€ç·¨è¼¯ç­‰
- é—œéµåƒæ•¸ï¼š
  - temperatureï¼šå‰µé€ æ€§æ§åˆ¶ï¼ˆ0æœ€ç¢ºå®šæ€§ï¼‰
  - max_tokensï¼šæ§åˆ¶å›æ‡‰é•·åº¦
  - presence/frequency penaltiesï¼šé¿å…é‡è¤‡
- è¨ˆè²»æ¨¡å¼ï¼šåŸºæ–¼è¼¸å…¥/è¼¸å‡ºtokensè¨ˆè²»

### 4-3 ç’°å¢ƒæº–å‚™èˆ‡APIè¨­ç½®
```python
# å®‰è£å¿…è¦å¥—ä»¶
!pip install openai requests pandas matplotlib numpy

# è¨­ç½®APIé‡‘é‘°ï¼ˆç’°å¢ƒè®Šæ•¸ç‚ºä½³ï¼‰
import os
import openai

# æ–¹æ³•1ï¼šå¾ç’°å¢ƒè®Šæ•¸å–å¾—ï¼ˆæ¨è–¦ï¼‰
openai.api_key = os.getenv("OPENAI_API_KEY")

# æ–¹æ³•2ï¼šç›´æ¥è¨­ç½®ï¼ˆä¸é©åˆæ­£å¼ç’°å¢ƒï¼‰
# openai.api_key = "your-api-key-here"

# æ¸¬è©¦é€£ç·š
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ]
)
print(response.choices[0].message['content'])
```

### 4-4 åŸºæœ¬APIå‘¼å«
```python
def query_gpt(prompt, system_msg="", model="gpt-3.5-turbo"):
    """åŸºæœ¬GPTæŸ¥è©¢å‡½å¼"""
    messages = []
    
    # åŠ å…¥ç³»çµ±è¨Šæ¯ï¼ˆå¦‚æœæä¾›ï¼‰
    if system_msg:
        messages.append({"role": "system", "content": system_msg})
    
    # åŠ å…¥ä½¿ç”¨è€…è¨Šæ¯
    messages.append({"role": "user", "content": prompt})
    
    # APIå‘¼å«
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=0,  # å°æ–¼æƒ…ç·’åˆ†æï¼Œä½æº«åº¦ç¢ºä¿ä¸€è‡´æ€§
        max_tokens=500
    )
    
    return response.choices[0].message['content']

# æ¸¬è©¦æƒ…ç·’åˆ†æ
news = "å°ç©é›»Q4è²¡å ±å„ªæ–¼å¸‚å ´é æœŸï¼Œç‡Ÿæ”¶å‰µæ–°é«˜ï¼Œä½†2023å¹´å±•æœ›ä¿å®ˆã€‚"
system_msg = "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é‡‘èæƒ…ç·’åˆ†æå¸«ï¼Œå°ˆé–€åˆ†æè²¡ç¶“æ–°èçš„æƒ…ç·’å‚¾å‘ã€‚"
prompt = f"åˆ†æä»¥ä¸‹æ–°èçš„æƒ…ç·’å‚¾å‘ï¼ˆæ­£é¢/è² é¢/ä¸­æ€§ï¼‰ä¸¦è§£é‡‹åŸå› ï¼š\n\n{news}"

result = query_gpt(prompt, system_msg)
print(result)
```

### 4-5 é‡‘èå°ˆæ¥­æç¤ºå·¥ç¨‹
- ç³»çµ±è¨Šæ¯å„ªåŒ–ï¼šå®šç¾©åˆ†æå¸«è§’è‰²èˆ‡å°ˆæ¥­èƒŒæ™¯
- æç¤ºè¨­è¨ˆæ ¸å¿ƒè¦ç´ ï¼š
  - ä»»å‹™æ˜ç¢ºåŒ–ï¼šæƒ…ç·’ã€å¼·åº¦ã€ç†ç”±
  - è¼¸å‡ºæ ¼å¼æ§åˆ¶ï¼šçµæ§‹åŒ–JSONä¾¿æ–¼è§£æ
  - æä¾›åˆ†ææ¡†æ¶èˆ‡æ¨™æº–
  - åŒ…å«å°‘æ¨£æœ¬ç¤ºä¾‹ï¼ˆfew-shot learningï¼‰
- ç¯„ä¾‹æç¤ºæ¨¡æ¿ï¼š

```python
# å°ˆæ¥­é‡‘èæƒ…ç·’åˆ†æç³»çµ±æç¤º
SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä½è³‡æ·±é‡‘èåˆ†æå¸«ï¼Œå°ˆç²¾æ–¼æƒ…ç·’åˆ†æã€‚è«‹åˆ†æä»¥ä¸‹è²¡ç¶“æ–‡å­—çš„æƒ…ç·’å‚¾å‘ï¼š
1. å°‡æƒ…ç·’è©•åˆ†ç‚º-1.0ï¼ˆæ¥µè² é¢ï¼‰åˆ°1.0ï¼ˆæ¥µæ­£é¢ï¼‰ä¹‹é–“çš„æ•¸å€¼
2. çµ¦å‡º0-100%çš„ä¿¡å¿ƒåº¦è©•åˆ†
3. åˆ—å‡ºæ”¯æŒä½ åˆ†æçš„é—œéµè©æˆ–å¥å­
4. è€ƒæ…®é‡‘èå°ˆæ¥­è¡“èªçš„å¯¦éš›å«ç¾©ï¼ˆå¦‚"ç²åˆ©é è­¦"ç‚ºè² é¢ï¼‰
5. ä»¥JSONæ ¼å¼è¿”å›çµæœï¼š{"score": æ•¸å€¼, "confidence": ç™¾åˆ†æ¯”, "key_factors": [å› ç´ åˆ—è¡¨]}
"""

# å¸¶ç¯„ä¾‹çš„æç¤ºæ¨¡æ¿ï¼ˆfew-shotï¼‰
FEW_SHOT_EXAMPLES = """
ç¯„ä¾‹1:
"å°ç©é›»å®£å¸ƒåŠ é€Ÿ3å¥ˆç±³é‡ç”¢ï¼Œå®¢æˆ¶éœ€æ±‚å¼·å‹"
{"score": 0.8, "confidence": 90, "key_factors": ["åŠ é€Ÿé‡ç”¢", "éœ€æ±‚å¼·å‹"]}

ç¯„ä¾‹2:
"æŸå…¬å¸ç‡Ÿæ”¶ä¸‹æ»‘15%ï¼Œä½†è™§æå¹…åº¦å„ªæ–¼é æœŸ"
{"score": -0.3, "confidence": 75, "key_factors": ["ç‡Ÿæ”¶ä¸‹æ»‘", "å„ªæ–¼é æœŸ"]}
"""
```

## ç¬¬äº”ç« ï¼šä½¿ç”¨GPT APIå–å¾—æƒ…ç·’æŒ‡æ•¸

### 5-1 æƒ…ç·’åˆ†ææµç¨‹è¨­è¨ˆ
- æ•´é«”å·¥ä½œæµï¼š
  - è³‡æ–™è’é›†ï¼šæ–°èAPIã€ç¤¾ç¾¤çˆ¬èŸ²
  - é è™•ç†ï¼šæ¸…æ´—ã€åˆ†å‰²ã€æ ¼å¼åŒ–
  - APIåˆ†æï¼šæ‰¹æ¬¡è™•ç†ã€è§£æçµæœ
  - æŒ‡æ•¸è¨ˆç®—ï¼šåŠ æ¬Šã€å¹³æ»‘ã€æ­£è¦åŒ–
- ç³»çµ±æ¶æ§‹è€ƒé‡ï¼š
  - æ“´å±•æ€§ï¼šæ”¯æ´å¤šè‚¡ç¥¨ã€å¤šä¾†æº
  - æ•ˆç‡ï¼šæ‰¹æ¬¡è™•ç†ç­–ç•¥ã€æˆæœ¬å„ªåŒ–
  - å¯é æ€§ï¼šéŒ¯èª¤è™•ç†ã€é‡è©¦æ©Ÿåˆ¶
  - åˆè¦æ€§ï¼šè³‡æ–™éš±ç§èˆ‡ä½¿ç”¨æ¢æ¬¾

### 5-2 æ¡é›†è²¡ç¶“æ–‡å­—è³‡æ–™
```python
import requests
import pandas as pd
from datetime import datetime, timedelta

# å¾æ–°èAPIå–å¾—ç‰¹å®šå…¬å¸æ–°è
def get_company_news(company, days=7, api_key="your_newsapi_key"):
    """å–å¾—å…¬å¸ç›¸é—œæ–°è"""
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days)
    
    url = f"https://newsapi.org/v2/everything?q={company}&from={start_date.strftime('%Y-%m-%d')}&to={end_date.strftime('%Y-%m-%d')}&sortBy=popularity&apiKey={api_key}"
    
    response = requests.get(url)
    if response.status_code == 200:
        news_data = response.json()
        articles = news_data.get('articles', [])
        return pd.DataFrame(articles)
    else:
        print(f"éŒ¯èª¤: {response.status_code}")
        return pd.DataFrame()
    
# å¾PTTè‚¡æ¿çˆ¬å–è¨è«–ï¼ˆç°¡åŒ–ç‰ˆï¼‰
def scrape_ptt_stock(stock_id, pages=3):
    """çˆ¬å–PTTè‚¡ç¥¨ç‰ˆç‰¹å®šè‚¡ç¥¨çš„è¨è«–"""
    import requests
    from bs4 import BeautifulSoup
    
    posts = []
    # å¯¦éš›å¯¦ä½œä¸­éœ€æ·»åŠ çˆ¬èŸ²é‚è¼¯
    # ...
    
    return pd.DataFrame(posts)
```

### 5-3 æ–‡å­—é è™•ç†èˆ‡å„ªåŒ–
```python
def preprocess_for_gpt(text, max_length=3000):
    """é è™•ç†æ–‡å­—ä»¥ä¾›GPTåˆ†æ"""
    # åŸºæœ¬æ¸…æ´—
    text = text.replace('\n', ' ').replace('\r', ' ')
    text = ' '.join(text.split())  # ç§»é™¤å¤šé¤˜ç©ºæ ¼
    
    # æˆªæ–·éé•·æ–‡å­—ï¼ˆé¿å…è¶…å‡ºtokené™åˆ¶ï¼‰
    if len(text) > max_length:
        text = text[:max_length] + "..."
    
    return text

# åˆ†å‰²éé•·æ–‡å­—
def chunk_long_text(text, chunk_size=3000, overlap=200):
    """å°‡é•·æ–‡å­—åˆ†å‰²ç‚ºè¼ƒå°å€å¡Šï¼Œä¿ç•™ä¸Šä¸‹æ–‡é‡ç–Š"""
    if len(text) <= chunk_size:
        return [text]
    
    chunks = []
    start = 0
    while start < len(text):
        end = min(start + chunk_size, len(text))
        if end < len(text) and end - start < chunk_size:
            # å°‹æ‰¾å¥å­é‚Šç•Œ
            sentence_end = text.rfind('. ', start, end) + 1
            if sentence_end > start:
                end = sentence_end
        
        chunks.append(text[start:end])
        start = end - overlap if end < len(text) else end
    
    return chunks
```

### 5-4 æƒ…ç·’åˆ†ææç¤ºè¨­è¨ˆ
```python
def create_sentiment_prompt(text, company_name=None):
    """å»ºç«‹æƒ…ç·’åˆ†ææç¤º"""
    system_msg = """ä½ æ˜¯ä¸€ä½å°ˆæ¥­é‡‘èåˆ†æå¸«ï¼Œå°ˆç²¾æ–¼æƒ…ç·’åˆ†æã€‚åˆ†ææ–‡å­—çš„æƒ…ç·’å‚¾å‘ï¼Œä¸¦è¿”å›ä»¥ä¸‹JSONæ ¼å¼ï¼š
{
  "sentiment_score": æƒ…ç·’åˆ†æ•¸ï¼ˆ-1åˆ°1ï¼Œè² é¢åˆ°æ­£é¢ï¼‰ï¼Œ
  "confidence": ä¿¡å¿ƒæ°´æº–ï¼ˆ0åˆ°1ï¼‰ï¼Œ
  "key_factors": [æ”¯æŒé€™ä¸€è©•åˆ†çš„é—œéµå› ç´ ]
}"""

    if company_name:
        prompt = f"åˆ†æä»¥ä¸‹æ–‡å­—å°{company_name}çš„æƒ…ç·’å‚¾å‘:\n\n{text}"
    else:
        prompt = f"åˆ†æä»¥ä¸‹è²¡ç¶“æ–‡å­—çš„æ•´é«”æƒ…ç·’å‚¾å‘:\n\n{text}"
    
    return system_msg, prompt

# å¤šé¡åˆ¥æƒ…ç·’åˆ†ææç¤º
def create_advanced_sentiment_prompt(text):
    """å»ºç«‹ç´°åˆ†æƒ…ç·’é¡åˆ¥çš„åˆ†ææç¤º"""
    system_msg = """ä½ æ˜¯ä¸€ä½å°ˆæ¥­é‡‘èåˆ†æå¸«ï¼Œå°ˆç²¾æ–¼å¤šç¶­åº¦æƒ…ç·’åˆ†æã€‚åˆ†ææ–‡å­—ä¸¦è¿”å›ä»¥ä¸‹JSONæ ¼å¼ï¼š
{
  "overall_score": ç¸½é«”æƒ…ç·’ï¼ˆ-1åˆ°1ï¼‰ï¼Œ
  "dimensions": {
    "growth": æˆé•·å‰æ™¯è©•åˆ†ï¼ˆ-1åˆ°1ï¼‰ï¼Œ
    "risk": é¢¨éšªè©•ä¼°ï¼ˆ-1åˆ°1ï¼‰ï¼Œ
    "management": ç®¡ç†å±¤è©•åƒ¹ï¼ˆ-1åˆ°1ï¼‰
  },
  "emotions": {
    "optimism": æ¨‚è§€ç¨‹åº¦ï¼ˆ0åˆ°1ï¼‰ï¼Œ
    "fear": ææ‡¼ç¨‹åº¦ï¼ˆ0åˆ°1ï¼‰ï¼Œ
    "confidence": ä¿¡å¿ƒç¨‹åº¦ï¼ˆ0åˆ°1ï¼‰
  },
  "key_sentences": [é—œéµå¥å­åˆ—è¡¨]
}"""

    prompt = f"é€²è¡Œå¤šç¶­åº¦æƒ…ç·’åˆ†æ:\n\n{text}"
    return system_msg, prompt
```

### 5-5 APIå‘¼å«èˆ‡çµæœè™•ç†
```python
import json
import time
import openai

def analyze_sentiment_with_gpt(text, company_name=None, model="gpt-3.5-turbo"):
    """ä½¿ç”¨GPTé€²è¡Œæƒ…ç·’åˆ†æ"""
    system_msg, prompt = create_sentiment_prompt(text, company_name)
    
    try:
        response = openai.ChatCompletion.create(
            model=model,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": prompt}
            ],
            temperature=0,
            max_tokens=250
        )
        
        # è§£æJSONå›æ‡‰
        response_text = response.choices[0].message['content']
        
        # è™•ç†éæ¨™æº–JSONè¼¸å‡ºï¼ˆæ¸…ç†ä¸¦è§£æï¼‰
        response_text = response_text.strip()
        if response_text.startswith("```json"):
            response_text = response_text.replace("```json", "").replace("```", "")
        
        sentiment_data = json.loads(response_text)
        return sentiment_data
    
    except Exception as e:
        print(f"åˆ†ææƒ…ç·’æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        time.sleep(2)  # é€Ÿç‡é™åˆ¶è™•ç†
        return {"sentiment_score": None, "confidence": None, "key_factors": []}

# æ‰¹æ¬¡è™•ç†æ–°èé …
def process_news_batch(news_df, company_name, max_items=None):
    """æ‰¹æ¬¡è™•ç†æ–°èæ–‡ç« """
    results = []
    
    # é™åˆ¶è™•ç†é …ç›®æ•¸ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if max_items:
        news_df = news_df.head(max_items)
    
    for i, row in news_df.iterrows():
        print(f"è™•ç†é …ç›® {i+1}/{len(news_df)}")
        content = row.get('content', '') or row.get('description', '')
        
        if not content:
            continue
            
        processed_text = preprocess_for_gpt(content)
        sentiment = analyze_sentiment_with_gpt(processed_text, company_name)
        
        # æ·»åŠ å…ƒè³‡æ–™
        sentiment['date'] = row.get('publishedAt', datetime.now().isoformat())
        sentiment['title'] = row.get('title', '')
        sentiment['source'] = row.get('source', {}).get('name', '')
        sentiment['url'] = row.get('url', '')
        
        results.append(sentiment)
        
        # é¿å…APIé™åˆ¶
        time.sleep(1)
    
    return pd.DataFrame(results)
```

### 5-6 æƒ…ç·’æŒ‡æ•¸å»ºæ§‹
```python
import numpy as np
import matplotlib.pyplot as plt

def calculate_sentiment_index(sentiment_df, decay_factor=0.2):
    """è¨ˆç®—æ™‚é–“åŠ æ¬Šæƒ…ç·’æŒ‡æ•¸"""
    # ç¢ºä¿æœ‰æ™‚é–“è³‡æ–™
    if 'date' not in sentiment_df.columns or sentiment_df.empty:
        print("è³‡æ–™ç¼ºå°‘æ—¥æœŸè³‡è¨Šæˆ–ç‚ºç©º")
        return pd.Series()
    
    # è½‰æ›æ—¥æœŸç‚ºdatetime
    sentiment_df['date'] = pd.to_datetime(sentiment_df['date'])
    
    # æ’åº
    sentiment_df = sentiment_df.sort_values('date')
    
    # è¨ˆç®—æ™‚é–“æ¬Šé‡ï¼ˆè¼ƒæ–° = æ›´é‡è¦ï¼‰
    max_date = sentiment_df['date'].max()
    sentiment_df['days_old'] = (max_date - sentiment_df['date']).dt.total_seconds() / (60*60*24)
    sentiment_df['time_weight'] = np.exp(-decay_factor * sentiment_df['days_old'])
    
    # æ‡‰ç”¨æ¬Šé‡ï¼ˆåŒ…æ‹¬ä¿¡å¿ƒåº¦ï¼‰
    sentiment_df['weighted_score'] = sentiment_df['sentiment_score'] * sentiment_df.get('confidence', 1) * sentiment_df['time_weight']
    
    # æŒ‰æ—¥è¨ˆç®—åŠ æ¬Šå¹³å‡
    daily_sentiment = sentiment_df.groupby(sentiment_df['date'].dt.date)['weighted_score'].mean()
    
    return daily_sentiment

# è¦–è¦ºåŒ–æƒ…ç·’æŒ‡æ•¸
def plot_sentiment_index(sentiment_index, stock_symbol):
    """ç¹ªè£½æƒ…ç·’æŒ‡æ•¸è¶¨å‹¢åœ–"""
    plt.figure(figsize=(12, 6))
    plt.plot(sentiment_index.index, sentiment_index.values, 'b-', linewidth=2)
    plt.axhline(y=0, color='r', linestyle='--', alpha=0.3)
    plt.fill_between(sentiment_index.index, 0, sentiment_index.values, 
                     where=(sentiment_index.values > 0), color='green', alpha=0.2)
    plt.fill_between(sentiment_index.index, 0, sentiment_index.values, 
                     where=(sentiment_index.values < 0), color='red', alpha=0.2)
    
    plt.title(f'{stock_symbol} æƒ…ç·’æŒ‡æ•¸è¶¨å‹¢', fontsize=15)
    plt.xlabel('æ—¥æœŸ')
    plt.ylabel('åŠ æ¬Šæƒ…ç·’åˆ†æ•¸')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    # æ·»åŠ å‡ç·š
    if len(sentiment_index) > 3:
        sentiment_index.rolling(window=3).mean().plot(
            color='orange', linestyle='-.', label='3æ—¥å‡ç·š')
        plt.legend()
    
    return plt
```

### 5-7 å¤šè‚¡ç¥¨ç¶œåˆåˆ†æ
```python
def batch_sentiment_analysis(stock_list, days=7, api_key=None):
    """æ‰¹æ¬¡åˆ†æå¤šæ”¯è‚¡ç¥¨çš„æ–°èæƒ…ç·’"""
    all_sentiment_data = {}
    
    for stock in stock_list:
        print(f"è™•ç† {stock}...")
        news = get_company_news(stock, days=days, api_key=api_key)
        
        if news.empty:
            print(f"æœªæ‰¾åˆ° {stock} çš„æ–°è")
            continue
        
        # è™•ç†æ–°è
        stock_sentiment = process_news_batch(news, stock, max_items=10)
        
        # è¨ˆç®—è©²è‚¡ç¥¨çš„æŒ‡æ•¸
        if not stock_sentiment.empty and 'sentiment_score' in stock_sentiment:
            try:
                all_sentiment_data[stock] = calculate_sentiment_index(stock_sentiment)
            except Exception as e:
                print(f"è¨ˆç®— {stock} æŒ‡æ•¸æ™‚å‡ºéŒ¯: {e}")
    
    return all_sentiment_data

# å¸‚å ´ç¶œåˆæƒ…ç·’æŒ‡æ•¸
def calculate_market_sentiment(sentiment_dict, weights=None):
    """è¨ˆç®—å¸‚å ´ç¶œåˆæƒ…ç·’æŒ‡æ•¸"""
    # è‚¡ç¥¨åˆ—è¡¨
    stocks = list(sentiment_dict.keys())
    
    if not stocks:
        return pd.Series()
    
    # é è¨­ç­‰æ¬Šé‡
    if weights is None:
        weights = {stock: 1/len(stocks) for stock in stocks}
    
    # ç¢ºä¿æ‰€æœ‰è‚¡ç¥¨è³‡æ–™å…·æœ‰ç›¸åŒçš„æ—¥æœŸç´¢å¼•
    all_dates = set()
    for stock in stocks:
        all_dates.update(sentiment_dict[stock].index)
    all_dates = sorted(list(all_dates))
    
    # å»ºç«‹å¸‚å ´æŒ‡æ•¸
    market_sentiment = pd.Series(0, index=all_dates)
    
    # åŠ æ¬Šè¨ˆç®—
    for stock in stocks:
        # é‡æ–°ç´¢å¼•ä»¥å°é½Šæ—¥æœŸ
        stock_sentiment = sentiment_dict[stock].reindex(all_dates).fillna(0)
        market_sentiment += stock_sentiment * weights.get(stock, 1/len(stocks))
    
    return market_sentiment
```

## ç¬¬å…­ç« ï¼šé‡‘èæƒ…ç·’åˆ†æçš„ç¾åœ¨èˆ‡æœªä¾†

### 6-1 ç•¶å‰ç”¢æ¥­æ‡‰ç”¨
- ä¸»è¦æ‡‰ç”¨å ´æ™¯ï¼š
  - é‡åŒ–äº¤æ˜“ï¼šæƒ…ç·’å› å­ç´å…¥å¤šå› å­æ¨¡å‹
  - é¢¨éšªç®¡ç†ï¼šæƒ…ç·’ç•°å¸¸ä½œç‚ºé¢¨éšªé è­¦
  - æŠ•è³‡ç ”ç©¶ï¼šè¼”åŠ©åŸºæœ¬é¢èˆ‡æŠ€è¡“é¢åˆ†æ
  - å¸‚å ´ç›£æ§ï¼šå³æ™‚ç›£æ¸¬å¸‚å ´æƒ…ç·’æ³¢å‹•
- æ¥­ç•Œé ˜å°è€…ï¼š
  - Bloomberg GPTï¼šå°ˆç‚ºé‡‘èé ˜åŸŸå„ªåŒ–çš„LLM
  - RavenPackï¼šå°ˆæ¥­æ–°èæƒ…ç·’è³‡æ–™æä¾›å•†
  - MarketPsychï¼šç¤¾ç¾¤åª’é«”æƒ…ç·’æŒ‡æ•¸
  - æŠ•è³‡éŠ€è¡Œè‡ªå»ºç³»çµ±

### 6-2 å¤šæ¨¡æ…‹æƒ…ç·’åˆ†æ
- è¶…è¶Šç´”æ–‡å­—ï¼šæ•´åˆåœ–åƒã€éŸ³è¨Šã€å½±ç‰‡
- æ‡‰ç”¨å ´æ™¯ï¼š
  - åˆ†æè²¡å ±å½±ç‰‡ä¸­CEOè¡¨æƒ…èˆ‡èªèª¿
  - è§£è®€è²¡ç¶“ç¯€ç›®ä¸»æŒäººæƒ…ç·’è®ŠåŒ–
  - è©•ä¼°æŠ•è³‡äººé›»è©±æœƒè­°ä¸­çš„èªæ°£
  - åˆ†æè²¡ç¶“åœ–è¡¨èˆ‡æ–‡å­—çš„çµåˆè§£è®€
- æŠ€è¡“æ¶æ§‹ï¼š
  - è¦–è¦ºTransformer (ViT) è™•ç†åœ–åƒ
  - èˆ‡LLMçµåˆçš„å¤šæ¨¡æ…‹èåˆå±¤
  - è·¨æ¨¡æ…‹æ³¨æ„åŠ›æ©Ÿåˆ¶

### 6-3 å³æ™‚æƒ…ç·’äº¤æ˜“ç³»çµ±
- ç³»çµ±æ¶æ§‹ï¼š
  - è³‡æ–™å±¤ï¼šå¤šæºè³‡æ–™è’é›†èˆ‡æ•´åˆ
  - åˆ†æå±¤ï¼šæƒ…ç·’åˆ†æèˆ‡è¨Šè™Ÿç”Ÿæˆ
  - ç­–ç•¥å±¤ï¼šè¨Šè™Ÿéæ¿¾èˆ‡äº¤æ˜“æ±ºç­–
  - åŸ·è¡Œå±¤ï¼šå§”è¨—ç®¡ç†èˆ‡é¢¨éšªæ§åˆ¶
- é—œéµæŠ€è¡“ï¼š
  - æµè™•ç†æ¡†æ¶ï¼ˆKafkaã€Flinkï¼‰
  - ä½å»¶é²APIå‘¼å«ç­–ç•¥
  - è¨Šè™Ÿæª¢é©—èˆ‡éæ¿¾æ¼”ç®—æ³•
  - é¢¨éšªé™åˆ¶æ©Ÿåˆ¶

### 6-4 å…ˆé€²AIæŠ€è¡“æ‡‰ç”¨
- å› æœæ¨è«–ï¼š
  - è­˜åˆ¥æƒ…ç·’èˆ‡å¸‚å ´é—œä¿‚çš„å› æœæ©Ÿåˆ¶
  - è™•ç†æ··æ·†è®Šæ•¸ï¼ˆå¦‚ï¼šé‡å¤§äº‹ä»¶ï¼‰
  - å»ºæ§‹åäº‹å¯¦æƒ…å¢ƒåˆ†æ
- å¼·åŒ–å­¸ç¿’ï¼š
  - è‡ªé©æ‡‰æƒ…ç·’é–¾å€¼èª¿æ•´
  - å¤šé€±æœŸè¨Šè™Ÿæœ€ä½³åŒ–
  - å¸‚å ´ç‹€æ…‹æ„ŸçŸ¥çš„ç­–ç•¥é¸æ“‡
- å¯è§£é‡‹AIï¼š
  - æƒ…ç·’åˆ¤æ–·æ ¹æ“šè¦–è¦ºåŒ–
  - å› å­å½±éŸ¿åŠ›åˆ†è§£
  - æ±ºç­–è·¯å¾‘è¿½è¹¤

### 6-5 é“å¾·è€ƒé‡èˆ‡æŒ‘æˆ°
- å¸‚å ´æ“ç¸±é¢¨éšªï¼š
  - æƒ…ç·’åˆ†æå¯èƒ½è¢«ç”¨æ–¼å¸‚å ´æ“ç¸±
  - å‡æ–°èæ”¾å¤§æ•ˆæ‡‰
  - é«˜é »æƒ…ç·’äº¤æ˜“çš„ç³»çµ±æ€§é¢¨éšª
- è³‡è¨Šä¸å°ç¨±ï¼š
  - å¤§å‹æ©Ÿæ§‹å„ªå‹¢æ“´å¤§
  - æ•£æˆ¶æŠ•è³‡äººçš„è³‡æ–™å£å£˜
  - æ¼”ç®—æ³•é€æ˜åº¦å•é¡Œ
- ç›£ç®¡ç’°å¢ƒï¼š
  - æƒ…ç·’åˆ†æç›¸é—œæ³•è¦ä¸å®Œå–„
  - è·¨å¸æ³•ç®¡è½„å€çš„æ³•éµæŒ‘æˆ°
  - éš±ç§ä¿è­·èˆ‡è³‡æ–™ä½¿ç”¨å¹³è¡¡

### 6-6 æœªä¾†ç™¼å±•æ–¹å‘
- å€‹æ€§åŒ–æƒ…ç·’åˆ†æï¼š
  - æŠ•è³‡äººé¢¨æ ¼å®¢è£½åŒ–
  - å€‹äººé¢¨éšªåå¥½é©é…
  - æƒ…ç·’åæ‡‰æ¨¡å¼è­˜åˆ¥
- è·¨è³‡ç”¢æƒ…ç·’æº¢å‡ºï¼š
  - è‚¡ç¥¨â†’å‚µåˆ¸â†’å•†å“æƒ…ç·’å‚³å°
  - ç”¢æ¥­é–“æƒ…ç·’é—œè¯ç¶²è·¯
  - å…¨çƒå¸‚å ´æƒ…ç·’é€£å‹•æ€§
- å…ˆé€²æŠ€è¡“æ•´åˆï¼š
  - è¯é‚¦å­¸ç¿’å¯¦ç¾éš±ç§ä¿è­·
  - é‡å­é‹ç®—åŠ é€Ÿæƒ…ç·’è™•ç†
  - å¤§è¦æ¨¡çŸ¥è­˜åœ–è­œå¢å¼·æƒ…ç·’ç†è§£
- å°ç£å¸‚å ´ç‰¹è‰²ï¼š
  - å°ç£å¸‚å ´æƒ…ç·’æŒ‡æ•¸åœ¨åœ°åŒ–
  - Aè‚¡èˆ‡æ¸¯è‚¡æƒ…ç·’åŒæ­¥æ€§ç ”ç©¶
  - å…©å²¸ä¸‰åœ°é‡‘èè¡“èªæ•´åˆ